import math, random, time, hashlib, requests, re
from lxml import etree

from scrapy import Spider

def gethref(a):
    return a.get('href')

class Crawl():
    def __init__(self):
        self.url = "https://security.snyk.io/vuln/"
        with open('synklst.txt', 'w') as f:
            f.write('')  # 写入空字符串，创建一个空文件

    def parse_id(self, vul):
        txt = {}
        res = requests.get("https://security.snyk.io/" + vul)
        html = etree.HTML(res.text)
        txt['id'] = vul[5:]
        txt['vulnerability'] = html.xpath('string(//h1[@class="vue--heading title"]/text())').strip()
        tmp = html.xpath('//a[@class="vue--anchor"]/text()')
        txt['cve'] = "CVE not available"
        txt['affects'] = "Unmanaged(C/C++)"
        txt['cwe'] = "CWE unknown"
        for t in tmp:
            if 'CVE' in t:
                txt['cve'] = t
            elif 'CWE' in t:
                txt['cwe'] = t
            else:
                txt['affects'] = t
        try:
            if txt['affects'] == 'Unmanaged(C/C++)':
                txt['affects'] += "::" + html.xpath('//span[@class="vue--anchor"]/text()')[0]
        except:
            print(vul)
        txt['versions'] = map(str.strip, html.xpath('//strong[@data-snyk-test="vuln versions"]/text()'))
        txt['vulscore'] = [i.get("data-snyk-test-score") for i in html.xpath('//div[@data-snyk-test="severity widget score"]')]
        try:
            txt['vullevel'] = html.xpath('//span[@class="vue--badge__text"]/text()')[0].strip()
        except:
            txt['vullevel'] = 'unknown'
        blocks = html.xpath('//div[@class="vue--markdown-to-html markdown-description"]')
        try:
            txt['howtofix'] = blocks[0].xpath('string(p)')
        except:
            txt['howtofix'] = 'unknown'
        try:
            txt['overview'] = blocks[1].xpath('string(p)')
        except:
            txt['overview'] = 'unknown'
        try:
            txt['references'] = blocks[2].xpath('ul/li/a/@href')
            txt['refdescription'] = blocks[2].xpath('ul/li/a/text()')
        except:
            txt['references'] = ['unknown']
            txt['refdescription'] = ['unknown']
        txt['exploitmaturity'] = html.xpath('string(//div[@data-snyk-test="CvssDetailsItem: Exploit Maturity"]/span/strong/text())').strip()
        txt['attackcomplexity'] = html.xpath('string(//div[@data-snyk-test="CvssDetailsItem: Attack Complexity"]/span/strong/text())').strip()
        #txt['attackvector'] = map(str.strip, html.xpath('//div[@data-snyk-test="CvssDetailsItem: Attack Vector"]/span/strong/text()'))
        txt['snykid'] = html.xpath('string(//li[@label="snyk-id"]/strong/text())')
        txt['published'] = html.xpath('string(//li[@label="published"]/strong/text())')
        txt['disclosed'] = html.xpath('string(//li[@label="disclosed"]/strong/text())')
        txt['credit'] = html.xpath('string(//li[@label="credit"]/strong/text())')
        return txt

    def spider(self):
        id_seens = set()
        total = 0
        i = 1
        while True:
            try:
                res = requests.get(self.url+str(i))
                i += 1
                html = etree.HTML(res.text)
                ids = []
                ids += map(gethref, html.xpath('//a[@data-snyk-test="vuln table title"]'))
                for id in ids:
                    if id in id_seens:
                        continue
                    id_seens.add(id)
                    result = self.parse_id(str(id))
                    total += 1
                    timestamp = time.time()
                    with open("synklst.txt", 'a') as f:
                        f.write("Crawl time: ")
                        f.write(str(timestamp))
                        f.write(' || ')
                        f.write(str(result))
                        f.write("\n")
            except:
                print("This crawl collects %d vulnerabilities" % total)
                exit()
            

s = Crawl()
params = s.spider()